apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-scripts
  labels:
    app: ai-knowledge-hub
    release: {{ .Release.Name }}
data:
  package.json: |
    {
      "name": "ai-knowledge-hub-scripts",
      "version": "1.0.0",
      "type": "module",
      "dependencies": {
        "ioredis": "^5.3.2",
        "chokidar": "^3.5.3",
        "glob": "^10.3.10",
        "@modelcontextprotocol/sdk": "^0.6.0",
        "zod": "^3.22.4",
        "@google/generative-ai": "^0.1.3",
        "tsx": "^4.7.0"
      }
    }

  watcher.ts: |
    import Redis from 'ioredis';
    import * as chokidar from 'chokidar';
    import * as fs from 'fs';
    import * as path from 'path';

    import { GoogleGenerativeAI } from "@google/generative-ai";

    // Configuration from environment or default
    const REDIS_URL = process.env.REDIS_URL || 'redis://localhost:6379';
    const PROJECTS_CONFIG = process.env.PROJECTS_CONFIG ? JSON.parse(process.env.PROJECTS_CONFIG) : [];
    const GEMINI_API_KEY = process.env.GEMINI_API_KEY;

    if (!GEMINI_API_KEY) {
      console.error("GEMINI_API_KEY is required");
      process.exit(1);
    }

    const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
    const model = genAI.getGenerativeModel({ model: "text-embedding-004" });

    console.log('Starting Ingestion Watcher...');
    console.log('Redis URL:', REDIS_URL);
    console.log('Projects to watch:', PROJECTS_CONFIG);

    const redisClient = new Redis(REDIS_URL);

    redisClient.on('error', (err) => console.error('Redis Client Error', err));

    // Simple Promise Queue for rate limiting
    class PromiseQueue {
      private queue: (() => Promise<void>)[] = [];
      private active = 0;
      private limit: number;

      constructor(limit: number) {
        this.limit = limit;
      }

      add(fn: () => Promise<void>) {
        this.queue.push(fn);
        this.next();
      }

      private next() {
        if (this.active >= this.limit || this.queue.length === 0) return;
        this.active++;
        const fn = this.queue.shift();
        if (fn) {
          fn().finally(() => {
            this.active--;
            this.next();
          });
        }
      }
    }

    // Limit to 3 concurrent requests to avoid Gemini rate limits during initial scan
    const queue = new PromiseQueue(3);

    async function connectRedis() {
      // ioredis connects automatically, but we can wait for ready
      // await redisClient.connect(); // Not needed for ioredis
      console.log('Connected to Redis');
      
      try {
        // FT.CREATE idx:knowledge ON JSON PREFIX 1 doc: SCHEMA $.content AS content TEXT $.project AS project TAG $.path AS path TAG $.embedding AS embedding VECTOR FLAT 6 TYPE FLOAT32 DIM 768 DISTANCE_METRIC COSINE
        await redisClient.call('FT.CREATE', 'idx:knowledge', 
          'ON', 'JSON', 
          'PREFIX', '1', 'doc:', 
          'SCHEMA', 
          '$.content', 'AS', 'content', 'TEXT',
          '$.project', 'AS', 'project', 'TAG',
          '$.path', 'AS', 'path', 'TAG',
          '$.embedding', 'AS', 'embedding', 'VECTOR', 'FLAT', '6', 'TYPE', 'FLOAT32', 'DIM', '768', 'DISTANCE_METRIC', 'COSINE'
        );
        console.log('Index idx:knowledge created');
      } catch (e: any) {
        if (e.message.includes('Index already exists')) {
          console.log('Index idx:knowledge already exists');
        } else {
          console.error('Error creating index:', e);
        }
      }
    }

    // Generate embedding using Gemini
    async function generateEmbedding(text: string): Promise<number[]> {
      try {
        // Add a small delay to further space out requests if needed
        await new Promise(resolve => setTimeout(resolve, 500));
        const result = await model.embedContent(text);
        const embedding = result.embedding;
        return embedding.values;
      } catch (error) {
        console.error("Error generating embedding:", error);
        return [];
      }
    }

    async function processFile(filePath: string, project: any) {
      if (!filePath.endsWith('.md')) return;

      queue.add(async () => {
        try {
          const content = fs.readFileSync(filePath, 'utf-8');
          const relativePath = path.relative(project.path, filePath);
          // Use a prefix that matches the index definition (doc:)
          const key = `doc:${project.redis_prefix}:${relativePath}`;

          console.log(`Processing file: ${filePath} -> Key: ${key}`);

          const embedding = await generateEmbedding(content);

          if (embedding.length === 0) {
              console.warn(`Skipping ${filePath} due to empty embedding`);
              return;
          }

          // JSON.SET key $ json_string
          const doc = {
            content: content,
            path: relativePath,
            project: project.name,
            embedding: embedding,
            updatedAt: new Date().toISOString()
          };
          
          await redisClient.call('JSON.SET', key, '$', JSON.stringify(doc));
          
          console.log(`Updated ${key} in Redis`);

        } catch (error) {
          console.error(`Error processing file ${filePath}:`, error);
        }
      });
    }

    async function startWatcher() {
      await connectRedis();

      PROJECTS_CONFIG.forEach((project: any) => {
        console.log(`Watching ${project.path} for project ${project.name}`);
        
        chokidar.watch(project.path, {
          ignored: /(^|[\/\\])\../, // ignore dotfiles
          persistent: true,
          ignoreInitial: false // Explicitly state we want initial scan
        }).on('add', path => processFile(path, project))
          .on('change', path => processFile(path, project))
          .on('ready', () => console.log(`Initial scan complete for ${project.name}`));
      });
    }

    startWatcher();

  mcp-server.ts: |
    import { Server } from "@modelcontextprotocol/sdk/server/index.js";
    import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
    import {
      CallToolRequestSchema,
      ListToolsRequestSchema,
    } from "@modelcontextprotocol/sdk/types.js";
    import { z } from "zod";
    import Redis from 'ioredis';
    import { GoogleGenerativeAI } from "@google/generative-ai";

    const REDIS_URL = process.env.REDIS_URL || 'redis://localhost:6379';
    const GEMINI_API_KEY = process.env.GEMINI_API_KEY;

    if (!GEMINI_API_KEY) {
      console.error("GEMINI_API_KEY is required");
      process.exit(1);
    }

    const redisClient = new Redis(REDIS_URL);
    const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
    const model = genAI.getGenerativeModel({ model: "text-embedding-004" });

    redisClient.on('error', (err) => console.error('Redis Client Error', err));

    const server = new Server(
      {
        name: "ai-knowledge-hub",
        version: "1.0.0",
      },
      {
        capabilities: {
          tools: {},
        },
      }
    );

    server.setRequestHandler(ListToolsRequestSchema, async () => {
      return {
        tools: [
          {
            name: "search_knowledge_base",
            description: "Search the AI Knowledge Hub for relevant documentation and code snippets using vector search.",
            inputSchema: {
              type: "object",
              properties: {
                query: {
                  type: "string",
                  description: "The search query (e.g., 'how to install', 'project architecture')",
                },
                project_id: {
                  type: "string",
                  description: "Optional project ID to filter results (e.g., 'elisabete-nogueira')",
                },
              },
              required: ["query"],
            },
          },
        ],
      };
    });

    async function generateEmbedding(text: string): Promise<number[]> {
        const result = await model.embedContent(text);
        return result.embedding.values;
    }

    server.setRequestHandler(CallToolRequestSchema, async (request) => {
      if (request.params.name === "search_knowledge_base") {
        const { query, project_id } = request.params.arguments as any;
        
        try {
            const embedding = await generateEmbedding(query);
            
            // Convert to Buffer for Redis
            const blob = Buffer.from(new Float32Array(embedding).buffer);

            // Construct filter query
            let filter = '*';
            if (project_id) {
                filter = `@project:{${project_id}}`;
            }

            // FT.SEARCH idx:knowledge filter=>[KNN 3 @embedding $vec AS score] PARAMS 2 vec blob DIALECT 2 RETURN 4 path content project score SORTBY score
            const args = [
                'idx:knowledge',
                `${filter}=>[KNN 3 @embedding $vec AS score]`,
                'PARAMS', '2', 'vec', blob,
                'DIALECT', '2',
                'RETURN', '4', 'content', 'path', 'project', 'score',
                'SORTBY', 'score'
            ];

            const response = await redisClient.call('FT.SEARCH', ...args) as any[];
            
            // Response format: [total, key1, [field1, val1, ...], key2, ...]
            const total = response[0];
            const results = [];

            for (let i = 1; i < response.length; i += 2) {
                const key = response[i];
                const fields = response[i+1]; 
                const doc: any = {};
                for (let j = 0; j < fields.length; j += 2) {
                    doc[fields[j]] = fields[j+1];
                }
                results.push(doc);
            }

            if (results.length === 0) {
                 return {
                    content: [
                        {
                            type: "text",
                            text: `No relevant documents found for "${query}".`,
                        },
                    ],
                };
            }

            const formattedResults = results.map(doc => {
                return `[${doc.project}] ${doc.path} (Score: ${doc.score})\n---\n${doc.content}\n---`;
            }).join('\n\n');

            return {
              content: [
                {
                  type: "text",
                  text: `Found ${total} documents for "${query}":\n\n${formattedResults}`,
                },
              ],
            };

        } catch (error: any) {
            console.error("Search error:", error);
            return {
                content: [
                    {
                        type: "text",
                        text: `Error performing search: ${error.message}`,
                    },
                ],
                isError: true,
            };
        }
      }
      throw new Error("Tool not found");
    });

    async function run() {
      const transport = new StdioServerTransport();
      await server.connect(transport);
      console.error("AI Knowledge Hub MCP Server running on stdio");
    }

    run().catch((error) => {
      console.error("Server error:", error);
      process.exit(1);
    });
