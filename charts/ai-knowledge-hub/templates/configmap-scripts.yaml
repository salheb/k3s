apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-scripts
  labels:
    app: ai-knowledge-hub
    release: {{ .Release.Name }}
data:
  package.json: |
    {
      "name": "ai-knowledge-hub-scripts",
      "version": "1.0.0",
      "type": "module",
      "dependencies": {
        "redis": "^4.6.0",
        "chokidar": "^3.5.3",
        "glob": "^10.3.10",
        "@modelcontextprotocol/sdk": "^0.6.0",
        "zod": "^3.22.4",
        "@google/generative-ai": "^0.1.3",
        "tsx": "^4.7.0"
      }
    }

  watcher.ts: |
    import { createClient } from 'redis';
    import * as chokidar from 'chokidar';
    import * as fs from 'fs';
    import * as path from 'path';

    import { GoogleGenerativeAI } from "@google/generative-ai";

    // Configuration from environment or default
    const REDIS_URL = process.env.REDIS_URL || 'redis://localhost:6379';
    const PROJECTS_CONFIG = process.env.PROJECTS_CONFIG ? JSON.parse(process.env.PROJECTS_CONFIG) : [];
    const GEMINI_API_KEY = process.env.GEMINI_API_KEY;

    if (!GEMINI_API_KEY) {
      console.error("GEMINI_API_KEY is required");
      process.exit(1);
    }

    const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
    const model = genAI.getGenerativeModel({ model: "text-embedding-004" });

    console.log('Starting Ingestion Watcher...');
    console.log('Redis URL:', REDIS_URL);
    console.log('Projects to watch:', PROJECTS_CONFIG);

    const redisClient = createClient({ url: REDIS_URL });

    redisClient.on('error', (err) => console.error('Redis Client Error', err));

    async function connectRedis() {
      await redisClient.connect();
      console.log('Connected to Redis');
    }

    // Generate embedding using Gemini
    async function generateEmbedding(text: string): Promise<number[]> {
      try {
        const result = await model.embedContent(text);
        const embedding = result.embedding;
        return embedding.values;
      } catch (error) {
        console.error("Error generating embedding:", error);
        // Return empty array or throw, for now returning empty to not crash watcher loop completely
        // but ideally should handle retry logic
        return [];
      }
    }

    async function processFile(filePath: string, project: any) {
      if (!filePath.endsWith('.md')) return;

      try {
        const content = fs.readFileSync(filePath, 'utf-8');
        const relativePath = path.relative(project.path, filePath);
        const key = `${project.redis_prefix}:doc:${relativePath}`;

        console.log(`Processing file: ${filePath} -> Key: ${key}`);

        // Store content and embedding
        // Note: Redis Stack supports vector search if configured. 
        // Here we just store the hash for simplicity of the example.
        // To fully use vector search, we'd need to create an index first.
        
        const embedding = await generateEmbedding(content);

        await redisClient.hSet(key, {
          content: content,
          path: relativePath,
          project: project.name,
          // Store embedding as bytes or JSON depending on Redis setup
          // For now, just storing metadata
          updatedAt: new Date().toISOString()
        });
        
        console.log(`Updated ${key} in Redis`);

      } catch (error) {
        console.error(`Error processing file ${filePath}:`, error);
      }
    }

    async function startWatcher() {
      await connectRedis();

      PROJECTS_CONFIG.forEach((project: any) => {
        console.log(`Watching ${project.path} for project ${project.name}`);
        
        chokidar.watch(project.path, {
          ignored: /(^|[\/\\])\../, // ignore dotfiles
          persistent: true
        }).on('add', path => processFile(path, project))
          .on('change', path => processFile(path, project));
      });
    }

    startWatcher();

  mcp-server.ts: |
    import { Server } from "@modelcontextprotocol/sdk/server/index.js";
    import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
    import {
      CallToolRequestSchema,
      ListToolsRequestSchema,
    } from "@modelcontextprotocol/sdk/types.js";
    import { z } from "zod";
    import { createClient } from 'redis';

    const REDIS_URL = process.env.REDIS_URL || 'redis://localhost:6379';
    const redisClient = createClient({ url: REDIS_URL });

    redisClient.on('error', (err) => console.error('Redis Client Error', err));

    async function connectRedis() {
      await redisClient.connect();
      console.log('Connected to Redis');
    }

    const server = new Server(
      {
        name: "ai-knowledge-hub",
        version: "1.0.0",
      },
      {
        capabilities: {
          tools: {},
        },
      }
    );

    server.setRequestHandler(ListToolsRequestSchema, async () => {
      return {
        tools: [
          {
            name: "search_knowledge_base",
            description: "Search for knowledge in the project documentation",
            inputSchema: {
              type: "object",
              properties: {
                query: {
                  type: "string",
                  description: "The search query",
                },
                project_id: {
                  type: "string",
                  description: "The project ID to search within (optional)",
                },
              },
              required: ["query"],
            },
          },
        ],
      };
    });

    server.setRequestHandler(CallToolRequestSchema, async (request) => {
      if (request.params.name === "search_knowledge_base") {
        const { query, project_id } = request.params.arguments as any;
        
        // In a real implementation, perform vector search here using Redis Stack
        // For now, we'll scan keys (inefficient but functional for demo)
        
        const keys = await redisClient.keys('*');
        // This is just a placeholder response
        return {
          content: [
            {
              type: "text",
              text: `Searching for "${query}" in project "${project_id || 'all'}". Found ${keys.length} documents in index. (Vector search not fully implemented in this placeholder)`,
            },
          ],
        };
      }
      throw new Error("Tool not found");
    });

    async function run() {
      await connectRedis();
      const transport = new StdioServerTransport();
      await server.connect(transport);
      console.error("AI Knowledge Hub MCP Server running on stdio");
    }

    run().catch((error) => {
      console.error("Server error:", error);
      process.exit(1);
    });
